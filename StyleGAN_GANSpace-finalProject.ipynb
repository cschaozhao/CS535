{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AiGN70it_epE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import legacy\n",
    "import click\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from torch_utils import misc\n",
    "from torch_utils import persistence\n",
    "from torch_utils.ops import conv2d_resample\n",
    "from torch_utils.ops import upfirdn2d\n",
    "from torch_utils.ops import bias_act\n",
    "from torch_utils.ops import fma\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'D:\\Rutgers_Study_Files\\\\2021Fall\\\\535\\\\final_project\\\\network-snapshot-010483.pkl'\n",
    "device = torch.device('cuda')\n",
    "outdir = 'D:\\\\Rutgers_Study_Files\\\\2021Fall\\\\535\\\\final_project\\\\generated'\n",
    "outdir_2 = 'D:\\\\Rutgers_Study_Files\\\\2021Fall\\\\535\\\\final_project\\\\generated_2'\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(url) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)  # type: ignore\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IFxAQhmjE4GH"
   },
   "outputs": [],
   "source": [
    "def expand_seed(seeds):\n",
    "    result = []\n",
    "    vector_size = G.z_dim\n",
    "    for seed in seeds:\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        result.append(rnd.randn(1, vector_size))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XUE0DvqlE6y8"
   },
   "outputs": [],
   "source": [
    "def generate_seeds(size):\n",
    "    seeds = []\n",
    "    for i in range(size):\n",
    "        seeds.append(random.randint(0,100000))\n",
    "    expanded_seeds = expand_seed(seeds)\n",
    "    return expanded_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A7wVKxjCD4Yl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Failed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cszha\\styleGAN\\stylegan2-ada-pytorch\\torch_utils\\ops\\bias_act.py:50: UserWarning: Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cszha\\styleGAN\\stylegan2-ada-pytorch\\torch_utils\\ops\\bias_act.py\", line 48, in _init\n",
      "    _plugin = custom_ops.get_plugin('bias_act_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"C:\\Users\\cszha\\styleGAN\\stylegan2-ada-pytorch\\torch_utils\\custom_ops.py\", line 64, in get_plugin\n",
      "    raise RuntimeError(f'Could not find MSVC/GCC/CLANG installation on this computer. Check _find_compiler_bindir() in \"{__file__}\".')\n",
      "RuntimeError: Could not find MSVC/GCC/CLANG installation on this computer. Check _find_compiler_bindir() in \"C:\\Users\\cszha\\styleGAN\\stylegan2-ada-pytorch\\torch_utils\\custom_ops.py\".\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n"
     ]
    }
   ],
   "source": [
    "def pca_basis(G, size = 10000):\n",
    "    \"\"\"\n",
    "    G: G model\n",
    "    size: sample size (bigger, better)\n",
    "    \"\"\"\n",
    "    c = None\n",
    "    z = generate_seeds(size)\n",
    "#     z = torch.tensor(z)\n",
    "#     print(z.shape)\n",
    "#     z = torch.randn([1, G.z_dim]).cuda()    \n",
    "    w = []\n",
    "    for i in range(size):\n",
    "        w.append(G.mapping(torch.tensor(z[i]).cuda(), c, truncation_psi=0.5, truncation_cutoff=8).cpu().numpy().tolist()) # not sure output size\n",
    "    # if w is 10000*p, then use the following code; otherwise, transfer to 10000*p first\n",
    "    w = np.array(w)\n",
    "    w = np.reshape(w,(size, 14 * 512))\n",
    "    pca = PCA()\n",
    "    pca.fit(w)\n",
    "    ratio = pca.explained_variance_ratio_\n",
    "    v = pca.components_\n",
    "    return v, ratio\n",
    "\n",
    "v, ratio = pca_basis(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.30027629e-02, 6.98511992e-02, 6.96037859e-02, ...,\n",
       "       1.64253376e-36, 6.52220093e-37, 1.40172936e-37])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = ratio.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\Rutgers_Study_Files\\\\2021Fall\\\\535\\\\final_project\\\\ratio.txt', 'wt') as f:\n",
    "    for i in rr:\n",
    "        print(i, file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e-jGxfc2Bdnu"
   },
   "outputs": [],
   "source": [
    "def steer_with_direction(G,startpoint,v,nth,num_step,size_step):#return seires of result output and show\n",
    "    \"\"\"\n",
    "    G: G model\n",
    "    startpoint: input seed (shape [1, seed.size])\n",
    "    v: pca basis of latent space\n",
    "    nth: number-th of pc loading used to update latent space\n",
    "    num_step: number of image generated (control parameter value)\n",
    "    size_step: step change of pc basis (control parameter value) (list)\n",
    "    \"\"\"\n",
    "    c = None\n",
    "    startpoint = startpoint.to(device)\n",
    "    direction = torch.from_numpy(v[nth]).to(device)\n",
    "    f, axarr = plt.subplots(1,num_step, figsize=(4*num_step,4), sharex='all', sharey='all')\n",
    "    for i in range(num_step):\n",
    "        w = G.mapping(startpoint, c, truncation_psi=0.5, truncation_cutoff=8).cpu()\n",
    "        w = np.reshape(w,(1, 14 * 512))\n",
    "        input = w.cuda() + size_step[i] * direction\n",
    "        input = np.reshape(input.cpu(), (1, 14, 512))\n",
    "        input = input.float().to(device)\n",
    "        img = G.synthesis(input, noise_mode='const', force_fp32=True)\n",
    "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seeds[seed_idx]:04d}.png')\n",
    "        axarr[i].imshow(img[0].cpu(), cmap='Blues',interpolation='nearest')\n",
    "        axarr[i].axis('off')\n",
    "    f.tight_layout(pad = 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steer_with_direction_generate(G,startpoint,v):#return seires of result output and show\n",
    "    \"\"\"\n",
    "    G: G model\n",
    "    startpoint: input seed (shape [1, seed.size])\n",
    "    v: pca basis of latent space\n",
    "    nth: number-th of pc loading used to update latent space\n",
    "    num_step: number of image generated (control parameter value)\n",
    "    size_step: step change of pc basis (control parameter value) (list)\n",
    "    \"\"\"\n",
    "    c = None\n",
    "    i = -150\n",
    "    for j in range(len(startpoint)):\n",
    "        nth = random.randint(0,200)\n",
    "        if i == -150:\n",
    "            i = 150\n",
    "        else:\n",
    "            i = -150\n",
    "        sp = torch.Tensor(startpoint[j])\n",
    "        sp = sp.to(device)\n",
    "        direction = torch.from_numpy(v[nth]).to(device)\n",
    "        w = G.mapping(sp, c, truncation_psi=0.5, truncation_cutoff=8).cpu()\n",
    "        w = np.reshape(w,(1, 14 * 512))\n",
    "        input = w.cuda() + i * direction\n",
    "        input = np.reshape(input.cpu(), (1, 14, 512))\n",
    "        input = input.float().to(device)\n",
    "        img = G.synthesis(input, noise_mode='const', force_fp32=True)\n",
    "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "        PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{j:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wTrkge7i_o9-"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    z = generate_seeds(2500)\n",
    "#     nth = 2000\n",
    "#     num_step = 1\n",
    "#     size_step = np.linspace(-10, 10, 1)\n",
    "#     steer_with_direction(G,z,v,nth,num_step,size_step)\n",
    "    steer_with_direction_generate(G,z,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "StyleGAN-GANSpace.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
